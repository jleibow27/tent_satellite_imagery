{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "from PIL import Image\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, mean_squared_error, f1_score\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moved the processed folder commands into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    folder path notation needs to be in string format. In jupyter, tab-autocomplete to avoid confusion. Examples: './example/',\n",
    "    '~/User/my/folder/is/here/'\n",
    "    \n",
    "    \"\"\"\n",
    "    #starting with a blank image list. We will then append that with each png file. \n",
    "    print(f'Building datafram from {folder_path} contents.')\n",
    "   \n",
    "    images = []\n",
    "    for index, file in enumerate(glob.glob('./Pete_sample/*.png')):\n",
    "        images.append(imageio.imread(file))\n",
    "\n",
    "    print(f'Library contains {len(images)} images')\n",
    "\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(f'{folder_path}*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            contents = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(contents)\n",
    "            \n",
    "    #lets user know how many images were processed\n",
    "    print(f'Processing {len(images)} .xml files') \n",
    "    \n",
    "#     sets up and df\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    \n",
    "#     this is the target feature, change as necessary\n",
    "    df['is_tent'] = (df['class']=='tent').astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building datafram from ./label_img_pics/train/ contents.\n",
      "Library contains 4 images\n",
      "Processing 4 .xml files\n"
     ]
    }
   ],
   "source": [
    "df = process_folder('./label_img_pics/train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding box data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = df[['xmin', 'ymin', 'xmax', 'ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df['class']\n",
    "tent = df['is_tent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = np.array(bboxes)\n",
    "encoder = LabelBinarizer()\n",
    "classes_onehot = encoder.fit_transform( classes )\n",
    "\n",
    "X = np.concatenate( [ bboxes ] , axis=1 )\n",
    "Y = np.array(tent)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a random forest classifier on the data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 1.0\n",
      "Score on testing set: 0.8461538461538461\n",
      "Score on training set: 1.0\n",
      "Score on testing set: 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "print(f'Score on training set: {rfc.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {rfc.score(X_test, y_test)}')\n",
    "\n",
    "rfc_preds_train = rfc.predict(X_train)\n",
    "rfc_preds_test = rfc.predict(X_test)\n",
    "print(f'Score on training set: {f1_score(y_train, rfc_preds_train)}')\n",
    "print(f'Score on testing set: {f1_score(y_test, rfc_preds_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
