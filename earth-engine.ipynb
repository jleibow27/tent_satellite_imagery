{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Image', 'bands': [{'id': 'elevation', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [432000, 144000], 'crs': 'EPSG:4326', 'crs_transform': [0.000833333333333, 0, -180, 0, -0.000833333333333, 60]}], 'version': 1494271934303000.0, 'id': 'srtm90_v4', 'properties': {'system:time_start': 950227200000, 'system:time_end': 951177600000, 'system:asset_size': 18827626666}}\n"
     ]
    }
   ],
   "source": [
    "# Import the Earth Engine Python Package\n",
    "import ee\n",
    "\n",
    "# Initialize the Earth Engine object, using the authentication credentials.\n",
    "ee.Initialize()\n",
    "\n",
    "# Print the information for an image asset.\n",
    "image = ee.Image('srtm90_v4')\n",
    "print(image.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee.Image({\n",
      "  \"type\": \"Invocation\",\n",
      "  \"arguments\": {\n",
      "    \"id\": \"LANDSAT/LT05/C01/T1_SR/LT05_034033_20000913\"\n",
      "  },\n",
      "  \"functionName\": \"Image.load\"\n",
      "})\n",
      "{'type': 'Image', 'bands': [{'id': 'B1', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'B2', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'B3', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'B4', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'B5', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'B6', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'B7', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'sr_atmos_opacity', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'sr_cloud_qa', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 255}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'pixel_qa', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}, {'id': 'radsat_qa', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 255}, 'dimensions': [7961, 7301], 'crs': 'EPSG:32613', 'crs_transform': [30, 0, 270285, 0, -30, 4414815]}], 'id': 'LANDSAT/LT05/C01/T1_SR/LT05_034033_20000913', 'version': 1538944486718967, 'properties': {'IMAGE_QUALITY': 9, 'SATELLITE': 'LANDSAT_5', 'SOLAR_AZIMUTH_ANGLE': 141.401031, 'CLOUD_COVER': 0, 'WRS_PATH': 34, 'EARTH_SUN_DISTANCE': 1.005947, 'system:time_start': 968865725989, 'LANDSAT_ID': 'LT05_L1TP_034033_20000913_20160918_01_T1', 'SENSING_TIME': '2000-09-13T17:22:05.9890880Z', 'ESPA_VERSION': '2_19_0c', 'SOLAR_ZENITH_ANGLE': 41.934059, 'system:footprint': {'type': 'LinearRing', 'coordinates': [[-107.02869086291923, 39.84432363800019], [-107.07980980087045, 39.85126661965529], [-107.08652717633666, 39.849697643108755], [-107.0897758455212, 39.8405819578208], [-107.11182940314823, 39.7707179631659], [-107.21879155445666, 39.413849310454374], [-107.37259194928556, 38.891052103694385], [-107.52433643751696, 38.368081812423796], [-107.55395385669085, 38.263097139745526], [-107.56063282665062, 38.23679490602129], [-107.55934893818782, 38.23317297774577], [-105.49311751312952, 37.930606804132815], [-105.48965894759056, 37.939600449971515], [-105.4779323992155, 37.97426299040739], [-105.4665343056877, 38.00837900396258], [-105.29373593893524, 38.543204771752215], [-105.00027724293751, 39.443187322446825], [-104.96794099898516, 39.54191304485849], [-107.02869086291923, 39.84432363800019]]}, 'WRS_ROW': 33, 'GEOMETRIC_RMSE_MODEL_Y': 3.358, 'LEVEL1_PRODUCTION_DATE': 1474209899000, 'CLOUD_COVER_LAND': 0, 'GEOMETRIC_RMSE_MODEL_X': 2.493, 'system:asset_size': 365532987, 'GEOMETRIC_RMSE_MODEL': 4.182, 'SR_APP_VERSION': 'LEDAPS_3.2.0', 'PIXEL_QA_VERSION': 'generate_pixel_qa_1.5.0', 'system:index': 'LT05_034033_20000913'}}\n"
     ]
    }
   ],
   "source": [
    "# Load a Landsat image\n",
    "img = ee.Image('LANDSAT/LT05/C01/T1_SR/LT05_034033_20000913')\n",
    "s\n",
    "# Print image object WITHOUT call to getInfo(); prints serialized request instructions\n",
    "print(img)\n",
    "\n",
    "# Print image object WITH call to getInfo(); prints image metadata\n",
    "print(img.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/wgF9y3Rh3HU79LGDygEs7Y2Bqp8DE-VhlDyjRjG4SAnrmzGwGb64P6g\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize the Earth Engine library.\n",
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow setup.\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (0.10.1)\n",
      "Requirement already satisfied: requests in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from folium) (2.22.0)\n",
      "Requirement already satisfied: numpy in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from folium) (1.17.2)\n",
      "Requirement already satisfied: branca>=0.3.0 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from folium) (0.3.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from folium) (2.10.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from requests->folium) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from requests->folium) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from requests->folium) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from requests->folium) (3.0.4)\n",
      "Requirement already satisfied: six in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from branca>=0.3.0->folium) (1.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/mariaflores/anaconda3/lib/python3.7/site-packages (from jinja2>=2.9->folium) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.1\n"
     ]
    }
   ],
   "source": [
    "# Folium setup.\n",
    "import folium\n",
    "print(folium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 22424\n",
      "-rw-r--r--@  1 mariaflores  staff    186112 Jan 23 10:16 1099.pdf\n",
      "drwxr-xr-x@ 20 mariaflores  staff       640 Feb 14 05:57 \u001b[1m\u001b[36mDSI\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 mariaflores  staff  11156792 Feb 10 10:48 ISLR Seventh Printing.pdf\n",
      "drwxr-xr-x@  5 mariaflores  staff       160 Jan 23 20:24 \u001b[1m\u001b[36mResume\u001b[m\u001b[m\n",
      "drwxr-xr-x   6 mariaflores  staff       192 Feb 14 06:22 \u001b[1m\u001b[36mai_platform_demo\u001b[m\u001b[m\n",
      "drwxr-xr-x   6 mariaflores  staff       192 Feb 13 06:42 \u001b[1m\u001b[36mairbnb data\u001b[m\u001b[m\n",
      "drwxr-xr-x   6 mariaflores  staff       192 Feb  6 22:02 \u001b[1m\u001b[36mcapstone_project\u001b[m\u001b[m\n",
      "-rw-r--r--   1 mariaflores  staff     28447 Feb 14 06:34 earth-engine.ipynb\n",
      "drwxr-xr-x   4 mariaflores  staff       128 Feb 13 06:42 \u001b[1m\u001b[36mgit files\u001b[m\u001b[m\n",
      "drwxr-xr-x   4 mariaflores  staff       128 Feb  6 21:19 \u001b[1m\u001b[36mgit notes\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 mariaflores  staff    100194 Feb 12 15:21 git-cheat-sheet-education.pdf\n",
      "drwxr-xr-x   4 mariaflores  staff       128 Feb 14 05:56 \u001b[1m\u001b[36mimage_classification_practice\u001b[m\u001b[m\n",
      "drwxr-xr-x@  4 mariaflores  staff       128 Feb 13 06:42 \u001b[1m\u001b[36mkepler-labelled-time-series-data\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 mariaflores  staff       160 Feb 13 06:42 \u001b[1m\u001b[36mnasa-asteroids-classification\u001b[m\u001b[m\n",
      "drwxr-xr-x   8 mariaflores  staff       256 Feb 14 05:57 \u001b[1m\u001b[36mproject_5\u001b[m\u001b[m\n",
      "-rw-r--r--   1 mariaflores  staff       215 Feb  5 08:48 scratch.md\n",
      "mkdir: ai_platform_demo: File exists\n",
      "total 16\n",
      "-rw-r--r--  1 mariaflores  staff     0 Feb 14 06:34 __init__.py\n",
      "drwxr-xr-x  5 mariaflores  staff   160 Feb 14 06:33 \u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m\n",
      "-rw-r--r--  1 mariaflores  staff  1164 Feb 14 06:26 config.py\n",
      "-rw-r--r--  1 mariaflores  staff  3802 Feb 14 06:32 model.py\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PATH = 'ai_platform_demo'\n",
    "\n",
    "!ls -l\n",
    "!mkdir {PACKAGE_PATH}\n",
    "!touch {PACKAGE_PATH}/__init__.py\n",
    "!ls -l {PACKAGE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ai_platform_demo/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PACKAGE_PATH}/config.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# INSERT YOUR BUCKET HERE!\n",
    "BUCKET = 'demo_bucket'\n",
    "\n",
    "# Specify names of output locations in Cloud Storage.\n",
    "FOLDER = 'fcnn-demo'\n",
    "JOB_DIR = 'gs://' + BUCKET + '/' + FOLDER + '/trainer'\n",
    "MODEL_DIR = JOB_DIR + '/model'\n",
    "LOGS_DIR = JOB_DIR + '/logs'\n",
    "\n",
    "# Pre-computed training and eval data.\n",
    "DATA_BUCKET = 'ee-docs-demos'\n",
    "TRAINING_BASE = 'training_patches'\n",
    "EVAL_BASE = 'eval_patches'\n",
    "\n",
    "# Specify inputs (Landsat bands) to the model and the response variable.\n",
    "opticalBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "thermalBands = ['B10', 'B11']\n",
    "BANDS = opticalBands + thermalBands\n",
    "RESPONSE = 'impervious'\n",
    "FEATURES = BANDS + [RESPONSE]\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "# Sizes of the training and evaluation datasets.\n",
    "TRAIN_SIZE = 16000\n",
    "EVAL_SIZE = 8000\n",
    "\n",
    "# Specify model training parameters.\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "BUFFER_SIZE = 3000\n",
    "OPTIMIZER = 'SGD'\n",
    "LOSS = 'MeanSquaredError'\n",
    "METRICS = ['RootMeanSquaredError']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "# INSERT YOUR BUCKET HERE!\n",
      "BUCKET = 'demo_bucket'\n",
      "\n",
      "# Specify names of output locations in Cloud Storage.\n",
      "FOLDER = 'fcnn-demo'\n",
      "JOB_DIR = 'gs://' + BUCKET + '/' + FOLDER + '/trainer'\n",
      "MODEL_DIR = JOB_DIR + '/model'\n",
      "LOGS_DIR = JOB_DIR + '/logs'\n",
      "\n",
      "# Pre-computed training and eval data.\n",
      "DATA_BUCKET = 'ee-docs-demos'\n",
      "TRAINING_BASE = 'training_patches'\n",
      "EVAL_BASE = 'eval_patches'\n",
      "\n",
      "# Specify inputs (Landsat bands) to the model and the response variable.\n",
      "opticalBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
      "thermalBands = ['B10', 'B11']\n",
      "BANDS = opticalBands + thermalBands\n",
      "RESPONSE = 'impervious'\n",
      "FEATURES = BANDS + [RESPONSE]\n",
      "\n",
      "# Specify the size and shape of patches expected by the model.\n",
      "KERNEL_SIZE = 256\n",
      "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
      "COLUMNS = [\n",
      "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
      "]\n",
      "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
      "\n",
      "# Sizes of the training and evaluation datasets.\n",
      "TRAIN_SIZE = 16000\n",
      "EVAL_SIZE = 8000\n",
      "\n",
      "# Specify model training parameters.\n",
      "BATCH_SIZE = 16\n",
      "EPOCHS = 50\n",
      "BUFFER_SIZE = 3000\n",
      "OPTIMIZER = 'SGD'\n",
      "LOSS = 'MeanSquaredError'\n",
      "METRICS = ['RootMeanSquaredError']\n",
      "\n",
      "\n",
      " 16\n"
     ]
    }
   ],
   "source": [
    "!cat {PACKAGE_PATH}/config.py\n",
    "\n",
    "from ai_platform_demo import config\n",
    "print('\\n\\n', config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ai_platform_demo/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PACKAGE_PATH}/model.py\n",
    "\n",
    "from . import config\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "# Dataset loading functions\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, config.FEATURES_DICT)\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  inputsList = [inputs.get(key) for key in config.FEATURES]\n",
    "  stacked = tf.stack(inputsList, axis=0)\n",
    "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "  return stacked[:,:,:len(config.BANDS)], stacked[:,:,len(config.BANDS):]\n",
    "\n",
    "def get_dataset(pattern):\n",
    "    glob = tf.io.gfile.glob(pattern)\n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_tfrecord)\n",
    "    dataset = dataset.map(to_tuple)\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset():\n",
    "    glob = 'gs://' + config.DATA_BUCKET + '/' + config.FOLDER + '/' + config.TRAINING_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.shuffle(config.BUFFER_SIZE).batch(config.BATCH_SIZE).repeat()\n",
    "    return dataset\n",
    "\n",
    "def get_eval_dataset():\n",
    "    glob = 'gs://' + config.DATA_BUCKET + '/' + config.FOLDER + '/' + config.EVAL_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.batch(1).repeat()\n",
    "    return dataset\n",
    "\n",
    "# A variant of the UNET model.\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "    return encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    return decoder\n",
    "\n",
    "def get_model():\n",
    "    inputs = layers.Input(shape=[None, None, len(config.BANDS)]) # 256\n",
    "    encoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
    "    encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
    "    encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
    "    encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
    "    encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
    "    center = conv_block(encoder4_pool, 1024) # center\n",
    "    decoder4 = decoder_block(center, encoder4, 512) # 16\n",
    "    decoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
    "    decoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
    "    decoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
    "    decoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.get(config.OPTIMIZER), \n",
    "        loss=losses.get(config.LOSS),\n",
    "        metrics=[metrics.get(metric) for metric in config.METRICS])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error executing an HTTP request: HTTP response code 401 with body '{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Anonymous caller does not have storage.objects.list access to ee-docs-demos.\",\n    \"errors\": [\n      {\n        \"message\": \"Anonymous caller does not have storage.objects.list access to ee-docs-demos.\",\n        \"domain\": \"global\",\n        \"reason\": \"required\",\n        \"locationType\": \"header\",\n        \"location\": \"Authorization\"\n      }\n    ]\n  }\n}\n'\n\t when reading gs://ee-docs-demos/fcnn-demo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-203d7b2a4ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mai_platform_demo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ai_platform_demo/model.py\u001b[0m in \u001b[0;36mget_eval_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_eval_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mglob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_BUCKET\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL_BASE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ai_platform_demo/model.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mglob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GZIP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_tfrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         for matching_filename in pywrap_tensorflow.GetMatchingFiles(\n\u001b[0;32m--> 384\u001b[0;31m             compat.as_bytes(pattern))\n\u001b[0m\u001b[1;32m    385\u001b[0m     ]\n\u001b[1;32m    386\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: Error executing an HTTP request: HTTP response code 401 with body '{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Anonymous caller does not have storage.objects.list access to ee-docs-demos.\",\n    \"errors\": [\n      {\n        \"message\": \"Anonymous caller does not have storage.objects.list access to ee-docs-demos.\",\n        \"domain\": \"global\",\n        \"reason\": \"required\",\n        \"locationType\": \"header\",\n        \"location\": \"Authorization\"\n      }\n    ]\n  }\n}\n'\n\t when reading gs://ee-docs-demos/fcnn-demo"
     ]
    }
   ],
   "source": [
    "from ai_platform_demo import model\n",
    "\n",
    "eval = model.get_eval_dataset()\n",
    "print(iter(eval.take(1)).next())\n",
    "\n",
    "model = model.get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ai_platform_demo/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PACKAGE_PATH}/task.py\n",
    "\n",
    "from . import config\n",
    "from . import model\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  training = model.get_training_dataset()\n",
    "  evaluation = model.get_eval_dataset()\n",
    "\n",
    "  m = model.get_model()\n",
    "\n",
    "  m.fit(\n",
    "      x=training,\n",
    "      epochs=config.EPOCHS, \n",
    "      steps_per_epoch=int(config.TRAIN_SIZE / config.BATCH_SIZE), \n",
    "      validation_data=evaluation,\n",
    "      validation_steps=int(config.EVAL_SIZE),\n",
    "      callbacks=[tf.keras.callbacks.TensorBoard(config.LOGS_DIR)])\n",
    "\n",
    "  tf.contrib.saved_model.save_keras_model(m, config.MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# INSERT YOUR PROJECT HERE!\n",
    "PROJECT = 'demo_project'\n",
    "\n",
    "JOB_NAME = 'demo_training_job_' + str(int(time.time()))\n",
    "TRAINER_PACKAGE_PATH = 'ai_platform_demo'\n",
    "MAIN_TRAINER_MODULE = 'ai_platform_demo.task'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: gcloud: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs submit training {JOB_NAME} \\\n",
    "    --job-dir {config.JOB_DIR}  \\\n",
    "    --package-path {TRAINER_PACKAGE_PATH} \\\n",
    "    --module-name {MAIN_TRAINER_MODULE} \\\n",
    "    --region {REGION} \\\n",
    "    --project {PROJECT} \\\n",
    "    --runtime-version 1.14 \\\n",
    "    --python-version 3.5 \\\n",
    "    --scale-tier basic-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
